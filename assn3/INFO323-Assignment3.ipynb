{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eugene Yakovlev - Completed\n",
    "May 8, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center\"> Drexel University </h1>\n",
    "<h2 style = \"text-align:center\"> College of Computing and Informatics</h2>\n",
    "<h2 style = \"text-align:center\">INFO 323: Cloud Computing and Big Data</h2>\n",
    "<h3 style = \"text-align:center\">Assignment 3</h3>\n",
    "<div style=\"text-align:center; border-style:solid; padding: 10px\">\n",
    "<div style=\"font-weight:bold\">Due Date: Sunday, May 17, 2020</div>\n",
    "This assignment counts for 15% of the final grade\n",
    "</div>\n",
    "\n",
    "### A. Assignment Overview\n",
    "This assignment provides the opportunity for you to practice with Spark programming basics. \n",
    "\n",
    "### B. What to Hand In\n",
    "\t\n",
    "Sumbit a completed this Jupyter notebook. \n",
    "\n",
    "### C. How to Hand In\n",
    "\n",
    "Submit your Jupyter notebook file through the course website in the Blackboard Learn system.\n",
    "\n",
    "### D. When to Hand In\n",
    "\n",
    "1. Submit your assignment no later than 11:59pm in the due date.\n",
    "2. There will be a 10% (absolute value) deduction for each day of lateness, to a maximum of 3 days; assignments will not be accepted beyond that point. Missing work will earn a zero grade.\n",
    "\n",
    "### E. Answer the following questions\n",
    "### Note: All the programming must be done in Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1: Data Exploration in Spark\n",
    "1. Copy the flights.csv file to HDFS system. \n",
    "2. Create a Spark DataFrom from the HDFS flights.csv file.\n",
    "3. Write Spark code the answer the following questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|       Saint Martin|    1|\n",
      "|       United States|            Romania|   12|\n",
      "|       United States|            Croatia|    2|\n",
      "|       United States|            Ireland|  291|\n",
      "|       United States|              India|   62|\n",
      "|               Egypt|      United States|   11|\n",
      "|       United States|            Grenada|   47|\n",
      "|          Costa Rica|      United States|  529|\n",
      "|             Senegal|      United States|   35|\n",
      "|       United States|       Sint Maarten|  290|\n",
      "|              Guyana|      United States|   52|\n",
      "|       United States|   Marshall Islands|   35|\n",
      "|               Malta|      United States|    2|\n",
      "|              Malawi|      United States|    1|\n",
      "|             Bolivia|      United States|   33|\n",
      "|            Anguilla|      United States|   34|\n",
      "|             Algeria|      United States|    9|\n",
      "|       United States|           Paraguay|   14|\n",
      "|           Gibraltar|      United States|    1|\n",
      "|Turks and Caicos ...|      United States|  193|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_df = spark.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\").csv(\"flights.csv\")\n",
    "flights_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. list all the unique destination countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|   DEST_COUNTRY_NAME|\n",
      "+--------------------+\n",
      "|                Chad|\n",
      "|            Anguilla|\n",
      "|              Russia|\n",
      "|            Paraguay|\n",
      "|             Senegal|\n",
      "|              Sweden|\n",
      "|            Kiribati|\n",
      "|              Guyana|\n",
      "|         Philippines|\n",
      "|            Malaysia|\n",
      "|                Fiji|\n",
      "|              Turkey|\n",
      "|              Malawi|\n",
      "|             Germany|\n",
      "|              Jordan|\n",
      "|               Palau|\n",
      "|Turks and Caicos ...|\n",
      "|              France|\n",
      "|              Greece|\n",
      "|              Taiwan|\n",
      "|British Virgin Is...|\n",
      "|            Dominica|\n",
      "|             Algeria|\n",
      "|            Slovakia|\n",
      "|               Macau|\n",
      "|           Argentina|\n",
      "|             Belgium|\n",
      "|              Angola|\n",
      "|             Ecuador|\n",
      "|               Qatar|\n",
      "|             Finland|\n",
      "|           Nicaragua|\n",
      "|               Ghana|\n",
      "|                Peru|\n",
      "|       United States|\n",
      "|               India|\n",
      "|               China|\n",
      "|             Curacao|\n",
      "|               Malta|\n",
      "|              Kuwait|\n",
      "|    Marshall Islands|\n",
      "|               Chile|\n",
      "|          Martinique|\n",
      "|      Cayman Islands|\n",
      "|             Bolivia|\n",
      "|             Nigeria|\n",
      "|               Italy|\n",
      "|            Suriname|\n",
      "|              Norway|\n",
      "|               Spain|\n",
      "|                Cuba|\n",
      "|          Mauritania|\n",
      "|          Guadeloupe|\n",
      "|             Denmark|\n",
      "|            Barbados|\n",
      "|             Ireland|\n",
      "|             Morocco|\n",
      "|              Panama|\n",
      "|          Cape Verde|\n",
      "|           Hong Kong|\n",
      "|           Venezuela|\n",
      "|             Ukraine|\n",
      "|             Iceland|\n",
      "|              Israel|\n",
      "|    Saint Barthelemy|\n",
      "|Saint Kitts and N...|\n",
      "|    French Polynesia|\n",
      "|         South Korea|\n",
      "|           Gibraltar|\n",
      "|             Uruguay|\n",
      "|Bonaire, Sint Eus...|\n",
      "|              Mexico|\n",
      "|               Aruba|\n",
      "|           Indonesia|\n",
      "|Saint Vincent and...|\n",
      "|         The Bahamas|\n",
      "|           Guatemala|\n",
      "|          Azerbaijan|\n",
      "|        Sint Maarten|\n",
      "|             Grenada|\n",
      "|Federated States ...|\n",
      "|             Liberia|\n",
      "|             Tunisia|\n",
      "|            Honduras|\n",
      "| Trinidad and Tobago|\n",
      "|        Saudi Arabia|\n",
      "|       French Guiana|\n",
      "|         Switzerland|\n",
      "|            Ethiopia|\n",
      "|              Latvia|\n",
      "|             Jamaica|\n",
      "|United Arab Emirates|\n",
      "|         Saint Lucia|\n",
      "|              Canada|\n",
      "|               Samoa|\n",
      "|      Czech Republic|\n",
      "|        Cook Islands|\n",
      "|              Brazil|\n",
      "|              Belize|\n",
      "| Antigua and Barbuda|\n",
      "|  Dominican Republic|\n",
      "|               Japan|\n",
      "|          Luxembourg|\n",
      "|         New Zealand|\n",
      "|           Greenland|\n",
      "|               Haiti|\n",
      "|              Poland|\n",
      "|            Portugal|\n",
      "|           Australia|\n",
      "|             Romania|\n",
      "|             Austria|\n",
      "|               Egypt|\n",
      "|          Costa Rica|\n",
      "|         El Salvador|\n",
      "|          Kazakhstan|\n",
      "|        Burkina Faso|\n",
      "|        South Africa|\n",
      "|             Bermuda|\n",
      "|             Bahrain|\n",
      "|            Colombia|\n",
      "|             Hungary|\n",
      "|            Pakistan|\n",
      "|      United Kingdom|\n",
      "|         Netherlands|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unique_dest_countries = flights_df.select(\"DEST_COUNTRY_NAME\").distinct()\n",
    "unique_dest_countries.show(unique_dest_countries.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. List all the unique origin countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "| ORIGIN_COUNTRY_NAME|\n",
      "+--------------------+\n",
      "|            Paraguay|\n",
      "|              Russia|\n",
      "|            Anguilla|\n",
      "|             Senegal|\n",
      "|              Sweden|\n",
      "|            Kiribati|\n",
      "|              Guyana|\n",
      "|         Philippines|\n",
      "|                Fiji|\n",
      "|              Turkey|\n",
      "|             Germany|\n",
      "|            Cambodia|\n",
      "|              Jordan|\n",
      "|               Palau|\n",
      "|Turks and Caicos ...|\n",
      "|              France|\n",
      "|              Greece|\n",
      "|British Virgin Is...|\n",
      "|              Taiwan|\n",
      "|            Dominica|\n",
      "|           Argentina|\n",
      "|              Angola|\n",
      "|             Belgium|\n",
      "|  Congo (Brazaville)|\n",
      "|             Ecuador|\n",
      "|               Qatar|\n",
      "|             Finland|\n",
      "|           Nicaragua|\n",
      "|               Ghana|\n",
      "|                Peru|\n",
      "|               India|\n",
      "|       United States|\n",
      "|               China|\n",
      "|             Curacao|\n",
      "|              Kuwait|\n",
      "|               Malta|\n",
      "|    Marshall Islands|\n",
      "|               Chile|\n",
      "|          Martinique|\n",
      "|      Cayman Islands|\n",
      "|             Croatia|\n",
      "|             Nigeria|\n",
      "|             Bolivia|\n",
      "|               Italy|\n",
      "|            Suriname|\n",
      "|              Norway|\n",
      "|               Spain|\n",
      "|                Cuba|\n",
      "|          Guadeloupe|\n",
      "|             Denmark|\n",
      "|            Barbados|\n",
      "|             Ireland|\n",
      "|             Morocco|\n",
      "|          Cape Verde|\n",
      "|              Panama|\n",
      "|           Hong Kong|\n",
      "|           Venezuela|\n",
      "|             Ukraine|\n",
      "|    Saint Barthelemy|\n",
      "|             Iceland|\n",
      "|              Israel|\n",
      "|Saint Kitts and N...|\n",
      "|    French Polynesia|\n",
      "|         South Korea|\n",
      "|Bonaire, Sint Eus...|\n",
      "|             Uruguay|\n",
      "|              Mexico|\n",
      "|               Aruba|\n",
      "|           Indonesia|\n",
      "|         The Bahamas|\n",
      "|Saint Vincent and...|\n",
      "|           Guatemala|\n",
      "|          Azerbaijan|\n",
      "|             Grenada|\n",
      "|        Sint Maarten|\n",
      "|Federated States ...|\n",
      "|             Tunisia|\n",
      "|            Honduras|\n",
      "| Trinidad and Tobago|\n",
      "|        Saudi Arabia|\n",
      "|       French Guiana|\n",
      "|         Switzerland|\n",
      "|            Ethiopia|\n",
      "|             Jamaica|\n",
      "|              Latvia|\n",
      "|United Arab Emirates|\n",
      "|        Saint Martin|\n",
      "|         Saint Lucia|\n",
      "|              Canada|\n",
      "|               Samoa|\n",
      "|      Czech Republic|\n",
      "|        Cook Islands|\n",
      "|              Brazil|\n",
      "|              Belize|\n",
      "| Antigua and Barbuda|\n",
      "|  Dominican Republic|\n",
      "|               Japan|\n",
      "|          Luxembourg|\n",
      "|         New Zealand|\n",
      "|           Greenland|\n",
      "|               Haiti|\n",
      "|              Poland|\n",
      "|            Portugal|\n",
      "|           Australia|\n",
      "|             Romania|\n",
      "|            Bulgaria|\n",
      "|             Austria|\n",
      "|          Costa Rica|\n",
      "|               Egypt|\n",
      "|          Kazakhstan|\n",
      "|         El Salvador|\n",
      "|        South Africa|\n",
      "|             Bermuda|\n",
      "|            Colombia|\n",
      "|             Hungary|\n",
      "|            Pakistan|\n",
      "|      United Kingdom|\n",
      "|         Netherlands|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unique_origin_countries = flights_df.select(\"ORIGIN_COUNTRY_NAME\").distinct()\n",
    "unique_origin_countries.show(unique_origin_countries.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. What are the origin and destination countries with maximum count?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME| count|\n",
      "+-----------------+-------------------+------+\n",
      "|    United States|      United States|358354|\n",
      "+-----------------+-------------------+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, desc, asc\n",
    "\n",
    "flights_df.orderBy(desc(\"count\")).show(1)\n",
    "\n",
    "# United States has 358,354 flights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. List all the flight records within the same country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME| count|\n",
      "+-----------------+-------------------+------+\n",
      "|    United States|      United States|358354|\n",
      "+-----------------+-------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_df.where(col(\"ORIGIN_COUNTRY_NAME\") == col(\"DEST_COUNTRY_NAME\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. List all the flights to United States ordered by their counts in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+------+\n",
      "|DEST_COUNTRY_NAME| ORIGIN_COUNTRY_NAME| count|\n",
      "+-----------------+--------------------+------+\n",
      "|    United States|            Bulgaria|     1|\n",
      "|    United States|        Saint Martin|     1|\n",
      "|    United States|          Kazakhstan|     1|\n",
      "|    United States|           Greenland|     1|\n",
      "|    United States|           Indonesia|     1|\n",
      "|    United States|  Congo (Brazaville)|     1|\n",
      "|    United States|             Hungary|     1|\n",
      "|    United States|             Ukraine|     1|\n",
      "|    United States|             Tunisia|     1|\n",
      "|    United States|            Cambodia|     1|\n",
      "|    United States|             Croatia|     2|\n",
      "|    United States|               Malta|     2|\n",
      "|    United States|Saint Vincent and...|     3|\n",
      "|    United States|       French Guiana|     4|\n",
      "|    United States|          Azerbaijan|     5|\n",
      "|    United States|            Ethiopia|    11|\n",
      "|    United States|      Czech Republic|    11|\n",
      "|    United States|               Egypt|    11|\n",
      "|    United States|             Romania|    12|\n",
      "|    United States|              Angola|    12|\n",
      "|    United States|            Pakistan|    12|\n",
      "|    United States|        Cook Islands|    12|\n",
      "|    United States|              Latvia|    13|\n",
      "|    United States|            Paraguay|    14|\n",
      "|    United States|             Bolivia|    14|\n",
      "|    United States|             Morocco|    15|\n",
      "|    United States|               Ghana|    15|\n",
      "|    United States|          Cape Verde|    16|\n",
      "|    United States|             Uruguay|    18|\n",
      "|    United States|             Finland|    19|\n",
      "|    United States|              Greece|    19|\n",
      "|    United States|              Kuwait|    24|\n",
      "|    United States|               Samoa|    25|\n",
      "|    United States|            Suriname|    27|\n",
      "|    United States|            Kiribati|    27|\n",
      "|    United States|                Fiji|    27|\n",
      "|    United States|             Senegal|    28|\n",
      "|    United States|          Martinique|    32|\n",
      "|    United States|        South Africa|    32|\n",
      "|    United States|              Poland|    33|\n",
      "|    United States|            Anguilla|    35|\n",
      "|    United States|    Marshall Islands|    35|\n",
      "|    United States|            Dominica|    36|\n",
      "|    United States|               Palau|    38|\n",
      "|    United States|    French Polynesia|    40|\n",
      "|    United States|             Nigeria|    43|\n",
      "|    United States|             Austria|    46|\n",
      "|    United States|          Guadeloupe|    47|\n",
      "|    United States|             Grenada|    47|\n",
      "|    United States|    Saint Barthelemy|    53|\n",
      "|    United States|              Guyana|    55|\n",
      "|    United States|               India|    62|\n",
      "|    United States|Bonaire, Sint Eus...|    63|\n",
      "|    United States|              Jordan|    64|\n",
      "|    United States|Federated States ...|    71|\n",
      "|    United States|        Saudi Arabia|    74|\n",
      "|    United States|             Curacao|    77|\n",
      "|    United States|         New Zealand|    77|\n",
      "|    United States|              Norway|    87|\n",
      "|    United States|            Barbados|    89|\n",
      "|    United States|              Turkey|    92|\n",
      "|    United States|               Qatar|    96|\n",
      "|    United States|British Virgin Is...|   101|\n",
      "|    United States|              Sweden|   101|\n",
      "|    United States|         Saint Lucia|   109|\n",
      "|    United States|              Israel|   112|\n",
      "|    United States| Antigua and Barbuda|   112|\n",
      "|    United States|          Luxembourg|   115|\n",
      "|    United States|         Philippines|   116|\n",
      "|    United States|             Denmark|   116|\n",
      "|    United States|            Portugal|   122|\n",
      "|    United States|Saint Kitts and N...|   123|\n",
      "|    United States|              Belize|   143|\n",
      "|    United States|              Russia|   151|\n",
      "|    United States|           Argentina|   153|\n",
      "|    United States|               Chile|   168|\n",
      "|    United States|           Nicaragua|   170|\n",
      "|    United States| Trinidad and Tobago|   175|\n",
      "|    United States|             Iceland|   177|\n",
      "|    United States|             Bermuda|   190|\n",
      "|    United States|               Haiti|   193|\n",
      "|    United States|Turks and Caicos ...|   204|\n",
      "|    United States|United Arab Emirates|   226|\n",
      "|    United States|             Belgium|   230|\n",
      "|    United States|           Australia|   235|\n",
      "|    United States|              Taiwan|   240|\n",
      "|    United States|           Venezuela|   258|\n",
      "|    United States|      Cayman Islands|   278|\n",
      "|    United States|        Sint Maarten|   290|\n",
      "|    United States|             Ireland|   291|\n",
      "|    United States|         Switzerland|   300|\n",
      "|    United States|                Peru|   315|\n",
      "|    United States|             Ecuador|   326|\n",
      "|    United States|           Guatemala|   327|\n",
      "|    United States|               Aruba|   348|\n",
      "|    United States|           Hong Kong|   381|\n",
      "|    United States|               Italy|   385|\n",
      "|    United States|            Honduras|   412|\n",
      "|    United States|                Cuba|   419|\n",
      "|    United States|               Spain|   424|\n",
      "|    United States|              Panama|   460|\n",
      "|    United States|         El Salvador|   486|\n",
      "|    United States|          Costa Rica|   560|\n",
      "|    United States|              Brazil|   578|\n",
      "|    United States|         Netherlands|   702|\n",
      "|    United States|             Jamaica|   714|\n",
      "|    United States|         South Korea|   754|\n",
      "|    United States|               China|   767|\n",
      "|    United States|            Colombia|   888|\n",
      "|    United States|              France|   960|\n",
      "|    United States|         The Bahamas|   991|\n",
      "|    United States|  Dominican Republic|  1282|\n",
      "|    United States|             Germany|  1343|\n",
      "|    United States|               Japan|  1501|\n",
      "|    United States|      United Kingdom|  1812|\n",
      "|    United States|              Mexico|  6490|\n",
      "|    United States|              Canada|  8177|\n",
      "|    United States|       United States|358354|\n",
      "+-----------------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_to_us = flights_df.where(col(\"DEST_COUNTRY_NAME\") == \"United States\").orderBy(asc(\"count\"))\n",
    "flights_to_us.show(flights_to_us.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2: Data Cleaning in Spark\n",
    "1. Copy the weather-samples.csv file to HDFS system. \n",
    "2. Create a Spark DataFrom from the HDFS weather-samples.csv file.\n",
    "3. Write Spark code the answer the following questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+------------+----------------------+------------------+----------------------+------------------+---------------------+-----------------+---------------------+---------------------+\n",
      "|number|air_pressure_9am|air_temp_9am|avg_wind_direction_9am|avg_wind_speed_9am|max_wind_direction_9am|max_wind_speed_9am|rain_accumulation_9am|rain_duration_9am|relative_humidity_9am|relative_humidity_3pm|\n",
      "+------+----------------+------------+----------------------+------------------+----------------------+------------------+---------------------+-----------------+---------------------+---------------------+\n",
      "|   0.0|          918.06|      74.822|                 271.1|         2.0803542|                 295.4|         2.8632832|                  0.0|              0.0|                42.42|                36.16|\n",
      "|   1.0|     917.3476881| 71.40384263|           101.9351794|       2.443009216|           140.4715485|       3.533323602|                  0.0|              0.0|          24.32869729|           19.4265968|\n",
      "|   2.0|          923.04|      60.638|                  51.0|        17.0678522|                  63.7|        22.1009672|                  0.0|             20.0|                  8.9|                14.46|\n",
      "|   3.0|     920.5027512| 70.13889487|           198.8321327|       4.337363056|           211.2033412|        5.19004536|                  0.0|              0.0|          12.18910187|          12.74254735|\n",
      "|   4.0|          921.16|      44.294|                 277.8|         1.8566602|                 136.5|         2.8632832|                  8.9|          14730.0|                92.41|                76.74|\n",
      "|   5.0|           915.3|      78.404|                 182.8|         9.9320136|                 189.0|        10.9833754|                 0.02|            170.0|                35.13|                33.93|\n",
      "|   6.0|     915.5988675| 70.04330432|           177.8754072|       3.745586538|           186.6066959|       4.589632429|                  0.0|              0.0|          10.65742166|          21.38565673|\n",
      "|   7.0|          918.07|       51.71|                 242.4|         2.5277422|                 271.6|         3.6462122|                  0.0|              0.0|                80.47|                74.92|\n",
      "|   8.0|          920.08|      80.582|                  40.7|         4.5186188|                  63.0|         5.8831522|                  0.0|              0.0|                29.58|                24.03|\n",
      "|   9.0|          915.01|      47.498|                 163.1|         4.9436374|                 195.9|         6.5766036|                  0.0|              0.0|                 88.6|                68.05|\n",
      "|  10.0|          919.65|      77.036|                  70.6|         3.8251674|                  85.5|         4.7646822|                  0.0|              0.0|                22.07|                32.13|\n",
      "|  11.0|          915.64|      45.716|                 241.6|         5.8607828|                 265.8|         8.0306146|                 0.55|           1770.0|                90.56|                79.09|\n",
      "|  12.0|          917.39|      49.784|                 204.1|         1.2750558|                 211.8|          2.013246|                  0.0|              0.0|                73.15|                58.43|\n",
      "|  13.0|          920.82|      62.438|                 213.6|         2.6172198|                 165.7|         3.3106712|                  0.0|              0.0|                43.64|                27.99|\n",
      "|  14.0|           911.0|      86.432|                 202.9|         1.2079476|                 162.9|          1.677705|                  0.0|              0.0|                15.19|                24.37|\n",
      "|  15.0|     922.3831312| 70.86526349|           36.17417478|       1.847278084|           58.42863249|       2.529142074|                  0.0|              0.0|          12.11088934|          14.80170596|\n",
      "|  16.0|          917.89|        null|                 169.2|         2.1922012|                 196.8|         2.9303914|                  0.0|              0.0|                48.99|                51.19|\n",
      "|  17.0|     916.9152554| 77.01896058|            234.539345|       2.274725297|           229.4741987|       2.906513109|                  0.0|              0.0|          21.03146177|          20.75568332|\n",
      "|  18.0|           918.8|      67.082|                 176.1|         4.8765292|                 183.4|         5.5699806|                  0.0|              0.0|                 18.9|                45.87|\n",
      "|  19.0|          922.04|      68.576|                  58.3|         9.5517338|                  81.9|        12.5716028|                  0.0|              0.0|                 7.54|                 7.74|\n",
      "+------+----------------+------------+----------------------+------------------+----------------------+------------------+---------------------+-----------------+---------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather_df = spark.read.option(\"inferSchema\", \"false\").option(\"header\", \"true\").csv(\"weather-samples.csv\")\n",
    "\n",
    "# Cast all column string types to double types\n",
    "for col in weather_df.columns:\n",
    "    weather_df = weather_df.withColumn(col, weather_df[col].cast(\"double\"))\n",
    "\n",
    "weather_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. List the columns of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['number',\n",
       " 'air_pressure_9am',\n",
       " 'air_temp_9am',\n",
       " 'avg_wind_direction_9am',\n",
       " 'avg_wind_speed_9am',\n",
       " 'max_wind_direction_9am',\n",
       " 'max_wind_speed_9am',\n",
       " 'rain_accumulation_9am',\n",
       " 'rain_duration_9am',\n",
       " 'relative_humidity_9am',\n",
       " 'relative_humidity_3pm']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b.  Print summary statistics for all the columns, e.g., using the describe() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+------------------+----------------------+------------------+----------------------+------------------+---------------------+------------------+---------------------+---------------------+\n",
      "|summary|            number| air_pressure_9am|      air_temp_9am|avg_wind_direction_9am|avg_wind_speed_9am|max_wind_direction_9am|max_wind_speed_9am|rain_accumulation_9am| rain_duration_9am|relative_humidity_9am|relative_humidity_3pm|\n",
      "+-------+------------------+-----------------+------------------+----------------------+------------------+----------------------+------------------+---------------------+------------------+---------------------+---------------------+\n",
      "|  count|              1095|             1092|              1090|                  1091|              1092|                  1092|              1091|                 1089|              1092|                 1095|                 1095|\n",
      "|   mean|             547.0|918.8825513141026| 64.93300141293575|    142.23551070020164| 5.508284242259157|    148.95351796495402| 7.019513529173236|  0.20307895225528005|294.10805227496246|   34.241402059256586|    35.34472714823471|\n",
      "| stddev|316.24357700987383|3.184161181422828|11.175514003266809|     69.13785928883635| 4.552813465529014|     67.23801294593558| 5.598209170789135|    1.593952125356949|1598.0787786596147|   25.472066802254194|   22.524079453607285|\n",
      "|    min|               0.0|           907.99|            36.752|                  15.5|         0.6934514|                  28.9|         1.1855782|                  0.0|               0.0|                 6.09|                  5.3|\n",
      "|    max|            1094.0|           929.32|            98.906|                 343.4|        23.5549782|                 312.2|        29.8407796|                24.02|           17704.0|                92.62|                92.25|\n",
      "+-------+------------------+-----------------+------------------+----------------------+------------------+----------------------+------------------+---------------------+------------------+---------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c.  Print the summary statistics for one column: air_pressure_9am."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary| air_pressure_9am|\n",
      "+-------+-----------------+\n",
      "|  count|             1092|\n",
      "|   mean|918.8825513141026|\n",
      "| stddev|3.184161181422828|\n",
      "|    min|           907.99|\n",
      "|    max|           929.32|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather_df.select(\"air_pressure_9am\").describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Drop rows with missing values in the air_pressure_9am column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1092"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df = weather_df.filter(weather_df.air_pressure_9am.isNotNull())\n",
    "weather_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. How many rows are dropped at the previous step?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 rows have been dropped from the previous filter step.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. What is the difference between the mean values of air_temp_9am before and after dropping all the missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary| air_pressure_9am|\n",
      "+-------+-----------------+\n",
      "|  count|             1092|\n",
      "|   mean|918.8825513141026|\n",
      "| stddev|3.184161181422828|\n",
      "|    min|           907.99|\n",
      "|    max|           929.32|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather_df.select(\"air_pressure_9am\").describe().show()\n",
    "\n",
    "# It appears that there is no difference in the mean after dropping the rows w the missing values.\n",
    "\n",
    "# BEFORE mean was 918.8825513141026\n",
    "# AFTER mean is 918.8825513141026\n",
    "\n",
    "# Pyspark does not count the missing values when executing the mean calculation, so after dropping the\n",
    "# rows w the missing values, it did not affect the mean calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. Compute correlation between two columns: rain_accumulation_9am and rain_duration_9am."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7298253479606396"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import corr\n",
    "\n",
    "weather_df.stat.corr(\"rain_accumulation_9am\", \"rain_duration_9am\")\n",
    "\n",
    "# 0.7298 score means that the two columns are highly correlated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute missing values. \n",
    "h. Instead of removing rows containing missing values, replace the values with the mean value for that column. First, load the avg function and make a copy of the original DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg, lit\n",
    "\n",
    "weather_df_copy = weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Next, iterate through each column in the DataFrame, compute the mean value for that column and then replace any missing values in that column with the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in weather_df.columns:\n",
    "    average = weather_df.select(avg(column)).take(1)[0][0]\n",
    "    weather_df_copy = weather_df_copy.fillna(average, subset=[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j. Print imputed data summary statistics. Call describe() to show the summary statistics for the original and imputed air_temp_9am. What is the difference between the mean values of air_temp_9am before and after the imputation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL\n",
      "+-------+------------------+\n",
      "|summary|      air_temp_9am|\n",
      "+-------+------------------+\n",
      "|  count|              1087|\n",
      "|   mean| 64.96896753152711|\n",
      "| stddev|11.154041196565856|\n",
      "|    min|            36.752|\n",
      "|    max|            98.906|\n",
      "+-------+------------------+\n",
      "\n",
      "AFTER FILL NAs w AVG\n",
      "+-------+-----------------+\n",
      "|summary|     air_temp_9am|\n",
      "+-------+-----------------+\n",
      "|  count|             1092|\n",
      "|   mean| 64.9689675315271|\n",
      "| stddev|11.12845263063525|\n",
      "|    min|           36.752|\n",
      "|    max|           98.906|\n",
      "+-------+-----------------+\n",
      "\n",
      "The difference between the mean values of air_temp_9am before and after the imputation is 1.4210854715202004e-14\n",
      "In other words, it basically didn't change because of how small the change actually is!\n"
     ]
    }
   ],
   "source": [
    "print(\"ORIGINAL\")\n",
    "weather_df.select(\"air_temp_9am\").describe().show()\n",
    "\n",
    "print(\"AFTER FILL NAs w AVG\")\n",
    "weather_df_copy.select(\"air_temp_9am\").describe().show()\n",
    "\n",
    "diff = 64.96896753152711 - 64.9689675315271\n",
    "print(\"The difference between the mean values of air_temp_9am before and after the imputation is {0}\".format(diff))\n",
    "print(\"In other words, it basically didn't change because of how small the change actually is!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
